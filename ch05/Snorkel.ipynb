{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Snorkel\n",
    "\n",
    "In this notebook we will use Snorkel to enrich our data such that tags with between 500-2,000 examples will be labeled using weak supervision to produce labels for enough examples to allow us to train an accurate full model that includes these new labels.\n",
    "\n",
    "More information about Snorkel can be found at [Snorkel.org](https://www.snorkel.org/) :) For a basic introduction to Snorkel, see the [Spam Tutorial](http://syndrome:8888/notebooks/snorkel-tutorials/spam/01_spam_tutorial.ipynb). For an introduction to Multi-Task Learning (MTL), see [Multi-Task Tutorial](http://syndrome:8888/notebooks/snorkel-tutorials/multitask/multitask_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snorkel Introduction\n",
    "\n",
    "from collections import OrderedDict \n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cupy\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import random\n",
    "import snorkel\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Make reproducible\n",
    "random.seed(1337)\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1337\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_LIMIT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'questions': {\n",
    "        'local': '../data/stackoverflow/Questions.Tags.{}.parquet/*.parquet',\n",
    "        's3': 's3://stackoverflow-events/08-05-2019/Questions.Tags.{}.parquet/part-00000-93547d3c-1f08-40b5-923e-89b961d01fc2-c000.snappy.parquet',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define a set of paths for each step for local and S3\n",
    "PATH_SET = 'local' # 's3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Examples for Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATHS['questions'][PATH_SET].format(TAG_LIMIT)\n",
    "\n",
    "df = dd.read_parquet(\n",
    "    path, \n",
    "    engine='pyarrow',\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_PostId</th>\n",
       "      <th>_AcceptedAnswerId</th>\n",
       "      <th>_Body</th>\n",
       "      <th>_Code</th>\n",
       "      <th>_Tags</th>\n",
       "      <th>_Label</th>\n",
       "      <th>_AnswerCount</th>\n",
       "      <th>_CommentCount</th>\n",
       "      <th>_FavoriteCount</th>\n",
       "      <th>_OwnerUserId</th>\n",
       "      <th>...</th>\n",
       "      <th>_AccountId</th>\n",
       "      <th>_UserId</th>\n",
       "      <th>_UserDisplayName</th>\n",
       "      <th>_UserDownVotes</th>\n",
       "      <th>_UserLocation</th>\n",
       "      <th>_ProfileImageUrl</th>\n",
       "      <th>_UserReputation</th>\n",
       "      <th>_UserUpVotes</th>\n",
       "      <th>_UserViews</th>\n",
       "      <th>_UserWebsiteUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108433</th>\n",
       "      <td>550148</td>\n",
       "      <td>550161.0</td>\n",
       "      <td>Does python have something like C++'s using keyword? In C++ you can often drastically improve the readability of your code by careful usage of the \"using\" keyword, for example: \\n\\nbecomes\\n\\nDoes something similar exist for python, or do I have to fully qualify everything?\\nI'll add the disclai...</td>\n",
       "      <td>void foo()\\n{\\n    std::vector&lt; std::map &lt;int, std::string&gt; &gt; crazyVector;\\n    std::cout &lt;&lt; crazyVector[0].begin()-&gt;first;\\n}\\n\\nvoid foo()\\n{\\n    using namespace std; // limited in scope to foo\\n    vector&lt; map &lt;int, string&gt; &gt; crazyVector;\\n    cout &lt;&lt; crazyVector[0].begin()-&gt;first;\\n}\\n</td>\n",
       "      <td>[python, namespaces, using]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5141.0</td>\n",
       "      <td>8123.0</td>\n",
       "      <td>Doug T.</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Charlottesville, VA United States</td>\n",
       "      <td>None</td>\n",
       "      <td>47950.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3484.0</td>\n",
       "      <td>http://o19s.com/doug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91946</th>\n",
       "      <td>3165563</td>\n",
       "      <td>3165672.0</td>\n",
       "      <td>Flexible logger class using standard streams in C++ i would like to create a flexible logger class. I want it to be able to output data to a file or to standard output. Also, i want to use streams. The class should look something like:\\n\\nThe  is an enum and defines the formatting. What i want t...</td>\n",
       "      <td>class Logger\\n{\\nprivate:\\n   std::ostream m_out; // or ofstream, iostream? i don't know\\npublic:\\n\\n   void useFile( std::string fname);\\n   void useStdOut();\\n\\n   void log( symbol_id si, int val );\\n   void log( symbol_id si, std::string str );\\n   //etc..\\n};\\n\\nsymbol_id\\nuse*\\nm_out\\nm_out...</td>\n",
       "      <td>[c++, logging, stream]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>350605.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142724.0</td>\n",
       "      <td>350605.0</td>\n",
       "      <td>PeterK</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Prague, Czech Republic</td>\n",
       "      <td>None</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69371</th>\n",
       "      <td>1227310</td>\n",
       "      <td>1227535.0</td>\n",
       "      <td>Question regarding Lucene scoring I have a question regarding Lucene scoring. I have two documents in the index, one contains \"my name\" and the other contains \"my first name\". When I search for the keyword \"my name\", the second document is listed above the first one. What I want is that if the d...</td>\n",
       "      <td></td>\n",
       "      <td>[lucene]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150287.0</td>\n",
       "      <td>...</td>\n",
       "      <td>877061.0</td>\n",
       "      <td>150287.0</td>\n",
       "      <td>Truong Do</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144449</th>\n",
       "      <td>18996773</td>\n",
       "      <td>18996887.0</td>\n",
       "      <td>Make UIView constantly fade in and out - completion:^{ possible infinite loop? I've written the following code to make my UIView constantly fade in and out. (FadeAlphaValue is a BOOL)... \\n\\nIt works but I have a feeling it's going to cause some weird crash if I let it run forever... I'm not to ...</td>\n",
       "      <td>-(void) fade {\\n    [UIView animateWithDuration:1.0\\n                     animations:^{\\n                         fadeView.alpha = (int)fadeAlphaValue;\\n                     }\\n                     completion:^(BOOL finished){\\n                         fadeAlphaValue=!fadeAlphaValue;\\n          ...</td>\n",
       "      <td>[ios, objective-c, animation, memory-management]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2057171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>405164.0</td>\n",
       "      <td>2057171.0</td>\n",
       "      <td>Albert Renshaw</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>https://i.stack.imgur.com/E9ThY.png</td>\n",
       "      <td>9237.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>http://www.Apps4Life.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136543</th>\n",
       "      <td>12978913</td>\n",
       "      <td>12980193.0</td>\n",
       "      <td>jquery visual website optimizer code I have a javascript code from visual website optimizer that will be placed on HTML header:\\n\\nbut I want to run this code only with this condition:\\n\\ni tried this but returns an error \"_vwo_code is not defined\"\\n\\nPlease help me on how can I solve this? Than...</td>\n",
       "      <td>var _vwo_code=(function(){\\nvar account_id=7237,\\nsettings_tolerance=2000,\\nlibrary_tolerance=1500,\\nuse_existing_jquery=true,\\n// DO NOT EDIT BELOW THIS LINE\\nf=false,d=document;return{use_existing_jquery:function(){return use_existing_jquery;},library_tolerance:function(){return library_tolera...</td>\n",
       "      <td>[jquery, web, optimization]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414930.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181133.0</td>\n",
       "      <td>414930.0</td>\n",
       "      <td>scoohh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>184.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _PostId  _AcceptedAnswerId  \\\n",
       "108433    550148           550161.0   \n",
       "91946    3165563          3165672.0   \n",
       "69371    1227310          1227535.0   \n",
       "144449  18996773         18996887.0   \n",
       "136543  12978913         12980193.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                              _Body  \\\n",
       "108433  Does python have something like C++'s using keyword? In C++ you can often drastically improve the readability of your code by careful usage of the \"using\" keyword, for example: \\n\\nbecomes\\n\\nDoes something similar exist for python, or do I have to fully qualify everything?\\nI'll add the disclai...   \n",
       "91946   Flexible logger class using standard streams in C++ i would like to create a flexible logger class. I want it to be able to output data to a file or to standard output. Also, i want to use streams. The class should look something like:\\n\\nThe  is an enum and defines the formatting. What i want t...   \n",
       "69371   Question regarding Lucene scoring I have a question regarding Lucene scoring. I have two documents in the index, one contains \"my name\" and the other contains \"my first name\". When I search for the keyword \"my name\", the second document is listed above the first one. What I want is that if the d...   \n",
       "144449  Make UIView constantly fade in and out - completion:^{ possible infinite loop? I've written the following code to make my UIView constantly fade in and out. (FadeAlphaValue is a BOOL)... \\n\\nIt works but I have a feeling it's going to cause some weird crash if I let it run forever... I'm not to ...   \n",
       "136543  jquery visual website optimizer code I have a javascript code from visual website optimizer that will be placed on HTML header:\\n\\nbut I want to run this code only with this condition:\\n\\ni tried this but returns an error \"_vwo_code is not defined\"\\n\\nPlease help me on how can I solve this? Than...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                              _Code  \\\n",
       "108433          void foo()\\n{\\n    std::vector< std::map <int, std::string> > crazyVector;\\n    std::cout << crazyVector[0].begin()->first;\\n}\\n\\nvoid foo()\\n{\\n    using namespace std; // limited in scope to foo\\n    vector< map <int, string> > crazyVector;\\n    cout << crazyVector[0].begin()->first;\\n}\\n   \n",
       "91946   class Logger\\n{\\nprivate:\\n   std::ostream m_out; // or ofstream, iostream? i don't know\\npublic:\\n\\n   void useFile( std::string fname);\\n   void useStdOut();\\n\\n   void log( symbol_id si, int val );\\n   void log( symbol_id si, std::string str );\\n   //etc..\\n};\\n\\nsymbol_id\\nuse*\\nm_out\\nm_out...   \n",
       "69371                                                                                                                                                                                                                                                                                                                 \n",
       "144449  -(void) fade {\\n    [UIView animateWithDuration:1.0\\n                     animations:^{\\n                         fadeView.alpha = (int)fadeAlphaValue;\\n                     }\\n                     completion:^(BOOL finished){\\n                         fadeAlphaValue=!fadeAlphaValue;\\n          ...   \n",
       "136543  var _vwo_code=(function(){\\nvar account_id=7237,\\nsettings_tolerance=2000,\\nlibrary_tolerance=1500,\\nuse_existing_jquery=true,\\n// DO NOT EDIT BELOW THIS LINE\\nf=false,d=document;return{use_existing_jquery:function(){return use_existing_jquery;},library_tolerance:function(){return library_tolera...   \n",
       "\n",
       "                                                   _Tags  _Label  \\\n",
       "108433                       [python, namespaces, using]       0   \n",
       "91946                             [c++, logging, stream]       0   \n",
       "69371                                           [lucene]       0   \n",
       "144449  [ios, objective-c, animation, memory-management]       0   \n",
       "136543                       [jquery, web, optimization]       0   \n",
       "\n",
       "        _AnswerCount  _CommentCount  _FavoriteCount  _OwnerUserId  ...  \\\n",
       "108433             6              0             3.0        8123.0  ...   \n",
       "91946              4              0             3.0      350605.0  ...   \n",
       "69371              4              0             NaN      150287.0  ...   \n",
       "144449             1              2             1.0     2057171.0  ...   \n",
       "136543             1              0             NaN      414930.0  ...   \n",
       "\n",
       "       _AccountId    _UserId  _UserDisplayName _UserDownVotes  \\\n",
       "108433     5141.0     8123.0           Doug T.          196.0   \n",
       "91946    142724.0   350605.0            PeterK           31.0   \n",
       "69371    877061.0   150287.0         Truong Do            0.0   \n",
       "144449   405164.0  2057171.0    Albert Renshaw           64.0   \n",
       "136543   181133.0   414930.0            scoohh            0.0   \n",
       "\n",
       "                            _UserLocation  \\\n",
       "108433  Charlottesville, VA United States   \n",
       "91946              Prague, Czech Republic   \n",
       "69371                                None   \n",
       "144449                        Atlanta, GA   \n",
       "136543                               None   \n",
       "\n",
       "                           _ProfileImageUrl _UserReputation  _UserUpVotes  \\\n",
       "108433                                 None         47950.0        2012.0   \n",
       "91946                                  None          4813.0        1242.0   \n",
       "69371                                  None            23.0           2.0   \n",
       "144449  https://i.stack.imgur.com/E9ThY.png          9237.0        1204.0   \n",
       "136543                                 None           184.0          14.0   \n",
       "\n",
       "       _UserViews           _UserWebsiteUrl  \n",
       "108433     3484.0      http://o19s.com/doug  \n",
       "91946       452.0                            \n",
       "69371        19.0                      None  \n",
       "144449     1784.0  http://www.Apps4Life.com  \n",
       "136543       56.0                      None  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 300)\n",
    "df.sample(frac=0.001).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable spaCy GPU Support\n",
    "\n",
    "That is, if you have a GPU (don't you have a GPU?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spaCy `Docs` in a `Dask` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Download the spaCy english model\n",
    "spacy.cli.download('en_core_web_lg')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# df['_Lower_Body'] = df['_Body'].apply(lambda x: x.lower())\n",
    "df['_SpacyDoc'] = df['_Body'].apply(lambda x: nlp(x), meta=('_Body', 'object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Train/Test/Development Datasets\n",
    "\n",
    "We'll need to validate our labeling functions (LFs) in Snorkel, so we need train, test and __development__ datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test_dev, y_train, y_test_dev = train_test_split(\n",
    "    df_sample, \n",
    "    df_sample['_Label'], \n",
    "    test_size=0.3,\n",
    "    random_state=1337,\n",
    ")\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "    X_test_dev,\n",
    "    y_test_dev,\n",
    "    test_size=0.66667,\n",
    "    random_state=1337,\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, X_dev.shape, y_train.shape, y_test.shape, y_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Function 1: Contains Tag\n",
    "\n",
    "The first labeling function we'll create is a keyword search. We'll look for whether the keyword is contained in the dataset. This would be helpful for a question about HTML with the tag `html` where `html` also appears in the body of the post.\n",
    "\n",
    "### Snorkel Proprocessors and LFs\n",
    "\n",
    "To do this we'll use a [`snorkel.preprocess.preprocessor`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html#snorkel.preprocess.preprocessor) called [`snorkel.preprocess.nlp.SpacyPreprocessor`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.nlp.SpacyPreprocessor.html) to create [`spacy.Docs`](https://spacy.io/api/doc) from our string documents. This will give us the document in various forms: text, a list of [`spacy.Tokens`](https://spacy.io/api/token), and a [`spacy.Doc.vector`](https://spacy.io/api/doc#vector) representation. Additional features of `SnorkelPreprocessor`, `spacy.Doc` and `spacy.Token` make this incredibly useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging `SpacyPreprocessor`\n",
    "\n",
    "*If you have trouble instantiating `SpacyPreprocessor` because `en_core_web_sm` won't load, restart/run all the notebook and the problem should resolve itself.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "spacy_processor = SpacyPreprocessor(\n",
    "    text_field='_Body',\n",
    "    doc_field='_Doc',\n",
    "    memoize=True,\n",
    "    gpu=True,\n",
    ")\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    \n",
    "    match = any(word in x._Doc.text for word in keywords)\n",
    "    if match:\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "def make_keyword_lf(keywords, label=ABSTAIN):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "        pre=[spacy_processor],\n",
    "    )\n",
    "\n",
    "\n",
    "# For each keyword, split on hyphen and create an LF that detects if that tag is present in the data\n",
    "keyword_lfs = OrderedDict()\n",
    "for label_set, index in zip(df['_Tag'].unique(), df['_Index'].unique()):\n",
    "    for label in label_set.split('-'):\n",
    "        keyword_lfs[label] = make_keyword_lf(label, label=index)\n",
    "\n",
    "list(keyword_lfs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply our LFs\n",
    "\n",
    "Let's try the first batch of tag keyword search LFs and see how they alone perform compared to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis, PandasLFApplier\n",
    "\n",
    "X_train = X_train[['_Lower_Text']]\n",
    "X_dev   = X_dev[['_Lower_Text']]\n",
    "\n",
    "applier = PandasLFApplier(\n",
    "    lfs=keyword_lfs.values(),\n",
    ")\n",
    "\n",
    "L_train = applier.apply(df=X_train)\n",
    "L_dev   = applier.apply(df=X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = LFAnalysis(L=L_dev, lfs=keyword_lfs.values()).lf_summary() # y_dev.as_matrix()\n",
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary[summary.index == 'keyword_base64']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply our LFs using PySpark\n",
    "\n",
    "For performance reasons, we want the parallel processing of PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from lib.utils import one_hot_encode\n",
    "\n",
    "PATHS = {\n",
    "    'bad_questions': {\n",
    "        'local': '../data/stackoverflow/Questions.Bad.{}.{}.parquet',\n",
    "        's3': 's3://stackoverflow-events/Questions.Bad.{}.{}.parquet',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define a set of paths for each step for local and S3\n",
    "PATH_SET = 'local' # 's3'\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName('Deep Products - Create Weak Labels')\\\n",
    "    .config('spark.dynamicAllocation.enabled', True)\\\n",
    "    .config('spark.shuffle.service.enabled', True)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "tag_limit, stratify_limit, bad_limit = 2000, 2000, 500\n",
    "\n",
    "bad_questions = spark.read.parquet(\n",
    "    PATHS['bad_questions'][PATH_SET].format(tag_limit, bad_limit)\n",
    ")\n",
    "\n",
    "# Redone from top for the moment\n",
    "from pyspark.sql import Row\n",
    "# from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "from snorkel.labeling.lf.nlp_spark import SparkNLPLabelingFunction\n",
    "\n",
    "\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "spacy_processor = SpacyPreprocessor(\n",
    "    text_field='_Body',\n",
    "    doc_field='_Doc',\n",
    "    memoize=True,\n",
    "    gpu=True,\n",
    ")\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    \n",
    "    match = any(word in x._Doc.text for word in keywords)\n",
    "    \n",
    "    if match:\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# For each keyword, split on hyphen and create an LF that detects if that tag is present in the data\n",
    "keyword_lfs = OrderedDict()\n",
    "for label_set, index in zip(df['_Tag'].unique(), df['_Index'].unique()):\n",
    "    for label in label_set.split('-'):\n",
    "        keyword_lfs[label] = make_keyword_lf(label, label=index)\n",
    "\n",
    "lf_1 = list(keyword_lfs.items())\n",
    "\n",
    "LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Vector Distances\n",
    "\n",
    "Now lets try using the [`vector`](https://spacy.io/api/doc#vector) feature of the [`spacy.Doc`](https://spacy.io/api/doc) which is returned in the `_Doc` field from the `SpacyPreprocessor` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
